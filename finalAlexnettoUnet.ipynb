{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 1080 (CNMeM is disabled, cuDNN 5105)\n",
      "/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "from scipy.misc import imread\n",
    "from keras.utils import np_utils\n",
    "\n",
    "#set up parameters will be used \n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 227, 227\n",
    "\n",
    "# number of channels, should try to get it.no matter what\n",
    "img_channels = 1 \n",
    "\n",
    "# normalization parameters\n",
    "img_Norm = 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 26 16 128 77 51\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "img_rows,img_cols=227,227\n",
    "# generate random data of rate of split ########随后随机生成\n",
    "NegetivePath = '/home/jupyter_1/Finalcombine/dataforAlextrain/nega'\n",
    "truedataPath = '/home/jupyter_1/Finalcombine/dataforAlextrain/true'\n",
    "splitRate = 0.6\n",
    "Nelisting = os.listdir(NegetivePath)\n",
    "nb_sampNe = np.size(Nelisting)\n",
    "nb_NeTrain = ceil(splitRate*nb_sampNe)\n",
    "nb_NeValidation = nb_sampNe-nb_NeTrain\n",
    "# print(nb_NeTrain)\n",
    "Polisting = os.listdir(truedataPath)\n",
    "nb_sampPo = np.size(Polisting)\n",
    "nb_PoTrain = ceil(splitRate*nb_sampPo)\n",
    "nb_PoValidation = nb_sampPo - nb_PoTrain\n",
    "\n",
    "#####################\n",
    "# data path\n",
    "datapath= '/home/jupyter_1/Finalcombine/Datasplit/'\n",
    "NeTrainpath= '/home/jupyter_1/Finalcombine/Datasplit/train/nega'\n",
    "NeValidaitionpath= '/home/jupyter_1/Finalcombine/Datasplit/validation/nega'\n",
    "PoTrainpath= '/home/jupyter_1/Finalcombine/Datasplit/train/true'\n",
    "PoValidaitionpath= '/home/jupyter_1/Finalcombine/Datasplit/validation/true'\n",
    "print(nb_sampNe,nb_NeTrain,nb_NeValidation,nb_sampPo,nb_PoTrain,nb_PoValidation)\n",
    "i =0\n",
    "for file in Nelisting:\n",
    "    i = i +1\n",
    "    im = Image.open(NegetivePath + '/' + file)   \n",
    "    img = im.resize((img_rows,img_cols))\n",
    "    gray = img   \n",
    "    if i <= nb_NeTrain:\n",
    "        gray.save( NeTrainpath+'/' +  file, \"JPEG\")\n",
    "    else :\n",
    "        gray.save( NeValidaitionpath+'/' +  file, \"JPEG\")\n",
    "        \n",
    "i=0            \n",
    "for file in Polisting:\n",
    "    i = i +1\n",
    "    im = Image.open(truedataPath + '/' + file)   \n",
    "    img = im.resize((img_rows,img_cols))\n",
    "    gray = img    \n",
    "    if i <= nb_PoTrain:\n",
    "        gray.save( PoTrainpath+'/' +  file, \"JPEG\")\n",
    "    else:\n",
    "        gray.save( PoValidaitionpath+'/' +  file, \"JPEG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 96, 55, 55)    11712       convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_1 (ZeroPadding2D)  (None, 96, 59, 59)    0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 96, 29, 29)    0           zeropadding2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNorma (None, 96, 29, 29)    192         maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 256, 25, 25)   614656      batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_2 (ZeroPadding2D)  (None, 256, 27, 27)   0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 256, 13, 13)   0           zeropadding2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNorma (None, 256, 13, 13)   512         maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 384, 11, 11)   885120      batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_3 (ZeroPadding2D)  (None, 384, 13, 13)   0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 384, 11, 11)   1327488     zeropadding2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_4 (ZeroPadding2D)  (None, 384, 13, 13)   0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "atrousconvolution2d_1 (AtrousCon (None, 256, 11, 11)   884992      zeropadding2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 256, 5, 5)     0           atrousconvolution2d_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 4096, 1, 1)    26218496    maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 4096, 1, 1)    16781312    convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 4096)          0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 2048)          8390656     flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 2048)          0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 2048)          4196352     dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 2048)          0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 2)             4098        dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 59315586\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model ALexnet \n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense, Dropout, Reshape, Permute, Activation,Input, merge,normalization\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D,AtrousConvolution2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam,SGD\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(96, 11, 11,subsample=(4,4),activation='relu',input_shape = (1,227,227)))\n",
    "model.add(ZeroPadding2D(padding=(2, 2)))\n",
    "model.add(MaxPooling2D((3, 3), strides=(2,2)))\n",
    "model.add(BatchNormalization(epsilon=1e-06, mode=0, axis=1))\n",
    "\n",
    "\n",
    "model.add (Convolution2D(256,5,5,subsample=(1,1),activation='relu'))\n",
    "model.add(ZeroPadding2D(padding=(1, 1)))\n",
    "model.add(MaxPooling2D((3, 3), strides=(2,2)))\n",
    "model.add(BatchNormalization(epsilon=1e-06, mode=0, axis=1))\n",
    "\n",
    "model.add(Convolution2D(384,3,3,subsample=(1,1)))\n",
    "model.add(ZeroPadding2D(padding=(1, 1), dim_ordering='th'))\n",
    "\n",
    "model.add(Convolution2D(384,3,3,subsample=(1,1)))\n",
    "model.add(ZeroPadding2D(padding=(1, 1), dim_ordering='th'))\n",
    "\n",
    "model.add(AtrousConvolution2D(256,3,3,subsample=(1,1)))\n",
    "\n",
    "model.add(MaxPooling2D((3, 3), strides=(2,2)))\n",
    "\n",
    "model.add(Convolution2D(4096,5,5,activation=\"relu\"))\n",
    "model.add(Convolution2D(4096,1,1,activation=\"relu\"))\n",
    "# model.add(AtrousConvolution2D(2,1,1))\n",
    "model.add( Flatten() )\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(2,activation='sigmoid'))\n",
    "\n",
    "\n",
    "sgd = SGD(lr=0.01, momentum=0.5, decay=0.1, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 103 images belonging to 2 classes.\n",
      "Found 67 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rotation_range=5.,\n",
    "             width_shift_range=0.1,\n",
    "             height_shift_range=0.1,\n",
    "            \n",
    "             zoom_range=0.2)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "train_data_dir = '/home/jupyter_1/Finalcombine/Datasplit/train'\n",
    "validation_data_dir = '/home/jupyter_1/Finalcombine/Datasplit/validation'\n",
    "\n",
    "test_datagen = ImageDataGenerator(rotation_range=5.,\n",
    "             width_shift_range=0.1,\n",
    "             height_shift_range=0.1,\n",
    "             \n",
    "             zoom_range=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        shuffle = True,\n",
    "        batch_size=1,\n",
    "        color_mode='grayscale',\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=1,\n",
    "        color_mode='grayscale',\n",
    "        shuffle = True,\n",
    "        class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2000/2000 [==============================] - 307s - loss: 0.3307 - acc: 0.8528 - val_loss: 0.3548 - val_acc: 0.8037\n",
      "Epoch 2/5\n",
      "2000/2000 [==============================] - 301s - loss: 0.2488 - acc: 0.8835 - val_loss: 0.3590 - val_acc: 0.8237\n",
      "Epoch 3/5\n",
      "2000/2000 [==============================] - 271s - loss: 0.2365 - acc: 0.8910 - val_loss: 0.3284 - val_acc: 0.8425\n",
      "Epoch 4/5\n",
      "2000/2000 [==============================] - 279s - loss: 0.2151 - acc: 0.8985 - val_loss: 0.3546 - val_acc: 0.8331\n",
      "Epoch 5/5\n",
      "2000/2000 [==============================] - 278s - loss: 0.2074 - acc: 0.9085 - val_loss: 0.3383 - val_acc: 0.8469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbd80f18320>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch =2000,\n",
    "        \n",
    "        nb_epoch=5,\n",
    "        validation_data=validation_generator,\n",
    "        nb_val_samples = 800,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n",
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# from keras.models import model_from_yaml\n",
    "# model_yaml = model.to_yaml()\n",
    "# with open(\"model.yaml\", \"w\") as yaml_file:\n",
    "#     yaml_file.write(model_yaml)\n",
    "# # serialize weights to HDF5\n",
    "# model.save_weights(\"model.h5\")\n",
    "# print(\"Saved model to disk\")\n",
    "# yaml_file = open('model.yaml', 'r')\n",
    "# loaded_model_yaml = yaml_file.read()\n",
    "# yaml_file.close()\n",
    "# loaded_model = model_from_yaml(loaded_model_yaml)\n",
    "# # load weights into new model\n",
    "# loaded_model.load_weights(\"model.h5\")\n",
    "# print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n",
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_yaml\n",
    "model_yaml = model.to_yaml()\n",
    "with open(\"model.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model1.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "yaml_file = open('model.yaml', 'r')\n",
    "loaded_model_yaml = yaml_file.read()\n",
    "yaml_file.close()\n",
    "loaded_model = model_from_yaml(loaded_model_yaml)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model1.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 712 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# final \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator( \n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        rotation_range=0.1,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=False)\n",
    "train_data_dir = '/home/jupyter_1/Finalcombine/data/'\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        shuffle = False,\n",
    "        batch_size=1,\n",
    "        color_mode='grayscale',\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 88.75%\n",
      "precision: 88.75%\n",
      "recall: 88.83%\n"
     ]
    }
   ],
   "source": [
    "loaded_model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy', 'f1score', 'precision', 'recall'])\n",
    "score = loaded_model.evaluate_generator(train_generator,val_samples=600)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[3], score[3]*100))\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[4], score[4]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 85.92%\n",
      "precision: 85.92%\n",
      "recall: 86.00%\n"
     ]
    }
   ],
   "source": [
    "loaded_model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy', 'f1score', 'precision', 'recall'])\n",
    "score = loaded_model.evaluate_generator(train_generator,val_samples=600)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[3], score[3]*100))\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[4], score[4]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 712 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# final \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator( \n",
    "        shear_range=0.,\n",
    "        zoom_range=0.,\n",
    "        rotation_range=0.,\n",
    "        width_shift_range=0.,\n",
    "        height_shift_range=0.,\n",
    "        horizontal_flip=False)\n",
    "train_data_dir = '/home/jupyter_1/Finalcombine/data/'\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        shuffle = False,\n",
    "        batch_size=1,\n",
    "        color_mode='grayscale',\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 88.08%\n",
      "precision: 88.08%\n",
      "recall: 88.17%\n"
     ]
    }
   ],
   "source": [
    "loaded_model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy', 'f1score', 'precision', 'recall'])\n",
    "score = loaded_model.evaluate_generator(train_generator,val_samples=600)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[3], score[3]*100))\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[4], score[4]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 712 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# final \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator( \n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        rotation_range=0.,\n",
    "        width_shift_range=0.,\n",
    "        height_shift_range=0.,\n",
    "        horizontal_flip=False)\n",
    "train_data_dir = '/home/jupyter_1/Finalcombine/data/'\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        shuffle = False,\n",
    "        batch_size=1,\n",
    "        color_mode='grayscale',\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 87.83%\n",
      "precision: 87.75%\n",
      "recall: 87.83%\n"
     ]
    }
   ],
   "source": [
    "loaded_model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy', 'f1score', 'precision', 'recall'])\n",
    "score = loaded_model.evaluate_generator(train_generator,val_samples=600)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[3], score[3]*100))\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[4], score[4]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 87.62%\n",
      "precision: 87.61%\n",
      "recall: 87.68%\n"
     ]
    }
   ],
   "source": [
    "loaded_model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy', 'f1score', 'precision', 'recall'])\n",
    "score = loaded_model.evaluate_generator(train_generator,val_samples=6000)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[3], score[3]*100))\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[4], score[4]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 712 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# final \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator( \n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        rotation_range=2.,\n",
    "        width_shift_range=0.,\n",
    "        height_shift_range=0.,\n",
    "        horizontal_flip=False)\n",
    "train_data_dir = '/home/jupyter_1/Finalcombine/data/'\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        shuffle = False,\n",
    "        batch_size=1,\n",
    "        color_mode='grayscale',\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 87.83%\n",
      "precision: 87.83%\n",
      "recall: 87.83%\n"
     ]
    }
   ],
   "source": [
    "loaded_model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy', 'f1score', 'precision', 'recall'])\n",
    "score = loaded_model.evaluate_generator(train_generator,val_samples=600)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[3], score[3]*100))\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[4], score[4]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
